{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Data Exploration and Data Cleaning with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our data loaded into our dataframe, we need to take a closer look at it to help us understand what it is we are working with. This is always the first step with any data science project. Let's see if we can answer the following questions: \n",
    "\n",
    "- How many rows does our dataframe have? \n",
    "- How many columns does it have?\n",
    "- What are the labels for the columns? Do the columns have names?\n",
    "- Are there any missing values in our dataframe? Does our dataframe contain any bad data?\n",
    "\n",
    "We can use the ```.head()``` method to peek at the top 5 rows of our dataframe. To see the number of rows and columns we can use the shape attribute:\n",
    "\n",
    "```df.shape``` \n",
    "\n",
    "Do you see 51 rows and 6 columns printed out below the cell? \n",
    "\n",
    "We saw that each column had a name. We can access the column names directly with the ```columns``` attribute.\n",
    "\n",
    "![Screenshot Output](https://raw.githubusercontent.com/GermanPaul12/STADS-Python-Course/main/Project%208%20Data%20Analysis/Salaries%20by%20college%20major/assets/1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values and Junk Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can proceed with our analysis we should try and figure out if there are any missing or junk data in our dataframe. That way we can avoid problems later on. In this case, we're going to look for NaN (Not A Number) values in our dataframe. NAN values are blank cells or cells that contain strings instead of numbers. Use the ```.isna()``` method and see if you can spot if there's a problem somewhere.\n",
    "\n",
    "```df.isna()```\n",
    "\n",
    "Did you find anything? Check the last couple of rows in the dataframe:\n",
    "\n",
    "```df.tail()```\n",
    "\n",
    "Aha! We have a row that contains some information regarding the source of the data with blank values for all the other other columns.\n",
    "\n",
    "![Screenshot Output](https://raw.githubusercontent.com/GermanPaul12/STADS-Python-Course/main/Project%208%20Data%20Analysis/Salaries%20by%20college%20major/assets/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the Last Row\n",
    "\n",
    "We don't want this row in our dataframe. There's two ways you can go about removing this row. The first way is to manually remove the row at index 50. The second way is to simply use the ```.dropna()``` method from pandas. Let's create a new dataframe without the last row and examine the last 5 rows to make sure we removed the last row:\n",
    "\n",
    "```clean_df = df.dropna()```\n",
    "\n",
    "```clean_df.tail()```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Columns and Individual Cells in a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find College Major with Highest Starting Salaries\n",
    "\n",
    "To access a particular column from a data frame we can use the square bracket notation, like so:\n",
    "\n",
    "```clean_df['Starting Median Salary']```\n",
    "\n",
    "You should see all the values printed out below the cell for just this column:\n",
    "\n",
    "![Screenshot Output](https://raw.githubusercontent.com/GermanPaul12/STADS-Python-Course/main/Project%208%20Data%20Analysis/Salaries%20by%20college%20major/assets/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the highest starting salary we can simply chain the ```.max()``` method.\n",
    "\n",
    "```clean_df['Starting Median Salary'].max()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest starting salary is $74,300. But which college major earns this much on average? For this, we need to know the row number or index so that we can look up the name of the major. Lucky for us, the ```.idxmax()``` method will give us index for the row with the largest value.\n",
    "\n",
    "```clean_df['Starting Median Salary'].idxmax()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is 43. To see the name of the major that corresponds to that particular row, we can use the ```.loc``` (location) property.\n",
    "\n",
    "```clean_df['Undergraduate Major'].loc[43]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are selecting both a column ('Undergraduate Major') and a row at index 43, so we are retrieving the value of a particular cell. You might see people using the double square brackets notation to achieve exactly the same thing: \n",
    "\n",
    "```clean_df['Undergraduate Major'][43]```\n",
    "\n",
    "![Screenshot Output](https://raw.githubusercontent.com/GermanPaul12/STADS-Python-Course/main/Project%208%20Data%20Analysis/Salaries%20by%20college%20major/assets/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't specify a particular column you can use the ```.loc``` property to retrieve an entire row:\n",
    "\n",
    "```clean_df.loc[43]```\n",
    "\n",
    "![Screenshot Output](https://raw.githubusercontent.com/GermanPaul12/STADS-Python-Course/main/Project%208%20Data%20Analysis/Salaries%20by%20college%20major/assets/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Now that we've found the major with the highest starting salary, can you write the code to find the following:\n",
    "\n",
    "- What college major has the highest mid-career salary? How much do graduates with this major earn? (Mid-career is defined as having 10+ years of experience).\n",
    "- Which college major has the lowest starting salary and how much do graduates earn after university?\n",
    "- Which college major has the lowest mid-career salary and how much can people expect to earn with this degree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Values & Adding Columns: Majors with the Most Potential vs Lowest Risk\n",
    "\n",
    "Lowest Risk Majors\n",
    "\n",
    "A low-risk major is a degree where there is a small difference between the lowest and highest salaries. In other words, if the difference between the 10th percentile and the 90th percentile earnings of your major is small, then you can be more certain about your salary after you graduate.\n",
    "\n",
    "How would we calculate the difference between the earnings of the 10th and 90th percentile? Well, Pandas allows us to do simple arithmetic with entire columns, so all we need to do is take the difference between the two columns:\n",
    "\n",
    "```clean_df['Mid-Career 90th Percentile Salary'] - clean_df['Mid-Career 10th Percentile Salary']```\n",
    "\n",
    "Alternatively, you can also use the ```.subtract()``` method.\n",
    "\n",
    "```clean_df['Mid-Career 90th Percentile Salary'].subtract(clean_df['Mid-Career 10th Percentile Salary'])```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this computation will be another Pandas dataframe column. We can add this to our existing dataframe with the ```.insert()``` method:\n",
    "\n",
    "```spread_col = clean_df['Mid-Career 90th Percentile Salary'] - clean_df['Mid-Career 10th Percentile Salary']```\n",
    "\n",
    "```clean_df.insert(1, 'Spread', spread_col)```\n",
    "\n",
    "```clean_df.head()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument is the position of where the column should be inserted. In our case, it's at position 1, so the second column.\n",
    "\n",
    "![Screenshot Output](https://raw.githubusercontent.com/GermanPaul12/STADS-Python-Course/main/Project%208%20Data%20Analysis/Salaries%20by%20college%20major/assets/6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting by the Lowest Spread\n",
    "\n",
    "To see which degrees have the smallest spread, we can use the ```.sort_values()``` method. And since we are interested in only seeing the name of the degree and the major, we can pass a list of these two column names to look at the ```.head()``` of these two columns exclusively.\n",
    "\n",
    "```low_risk = clean_df.sort_values('Spread')```\n",
    "\n",
    "```low_risk[['Undergraduate Major', 'Spread']].head()```\n",
    "\n",
    "Does ```.sort_values()``` sort in ascending or descending order? To find out, check out the Pandas documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "You can also bring up the quick documentation with shift + tab on your keyboard directly in the Python notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Using the .sort_values() method, can you find the degrees with the highest potential? Find the top 5 degrees with the highest values in the 90th percentile. \n",
    "\n",
    "Also, find the degrees with the greatest spread in salaries. Which majors have the largest difference between high and low earners after graduation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Pivoting Data with Pandas\n",
    "\n",
    "Often times you will want to sum rows that belong to a particular category. For example, which category of degrees has the highest average salary? Is it STEM, Business or HASS (Humanities, Arts, and Social Science)? \n",
    "\n",
    "To answer this question we need to learn to use the ```.groupby()``` method. This allows us to manipulate data similar to a Microsoft Excel Pivot Table.\n",
    "\n",
    "We have three categories in the 'Group' column: STEM, HASS and Business. Let's count how many majors we have in each category:\n",
    "\n",
    "```clean_df.groupby('Group').count()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Challenge\n",
    "\n",
    "Now can you use the ```.mean()``` method to find the average salary by group? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number formats in the Output\n",
    "\n",
    "The above is a little hard to read, isn't it? We can tell Pandas to print the numbers in our notebook to look like 1,012.45 with the following line:\n",
    "\n",
    "```pd.options.display.float_format = '{:,.2f}'.format```\n",
    " \n",
    "Ah, that's better, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PayScale dataset used in this lesson was from 2008 and looked at the prior 10 years. Notice how Finance ranked very high on post-degree earnings at the time. However, we all know there was a massive financial crash in that year. Perhaps things have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
